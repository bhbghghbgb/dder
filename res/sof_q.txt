Creating a customized out order Golang channel.

### Context

In this example, I use a [Priority Queue](https://en.wikipedia.org/wiki/Priority_queue) order. The default Go `chan` is FIFO, which doesn't allow prioritization. To overcome this limitation, I tried building a `ChannelizedPriorityQueue` exposing an `In` and `Out` channel (Not sure if it's possible to [overload the operator](https://en.wikipedia.org/wiki/Operator_overloading) `<-chan` and `chan<-`).

1. Using the example from [`container/heap`'s documentation](https://pkg.go.dev/container/heap#example-package-PriorityQueue). Code a generic `Priority Queue`.

```go
// https://pkg.go.dev/container/heap#example-package-PriorityQueue

// Item represents a generic item with a priority.
type Item[T any] struct {
	Value    T
	Priority int // Higher value means higher priority
	index    int // Index in the heap (for heap.Interface)
}

// UnboundedPriorityQueue implements heap.Interface and holds Items.
type UnboundedPriorityQueue[T any] []*Item[T]

func (pq UnboundedPriorityQueue[T]) Len() int { return len(pq) }

// We want higher priority to have a lower index in the heap for removal.
func (pq UnboundedPriorityQueue[T]) Less(i, j int) bool {
	return pq[i].Priority > pq[j].Priority
}

func (pq UnboundedPriorityQueue[T]) Swap(i, j int) {
	pq[i], pq[j] = pq[j], pq[i]
	pq[i].index = i
	pq[j].index = j
}

func (pq *UnboundedPriorityQueue[T]) Push(x any) {
	n := len(*pq)
	item := x.(*Item[T])
	item.index = n
	*pq = append(*pq, item)
}

func (pq *UnboundedPriorityQueue[T]) Pop() any {
	old := *pq
	n := len(old)
	item := old[n-1]
	old[n-1] = nil  // avoid memory leaks
	item.index = -1 // for safety
	*pq = old[0 : n-1]
	return item
}

// update modifies the priority of an Item in the queue.
func (pq *UnboundedPriorityQueue[T]) update(item *Item[T], value T, priority int) {
	item.Value = value
	item.Priority = priority
	heap.Fix(pq, item.index)
}

// Test the priority queue if you need
func priorityQueueTest() {
	// Create a new priority queue
	pq := make(UnboundedPriorityQueue[string], 0)
	heap.Init(&pq)

	// Add items to the priority queue
	heap.Push(&pq, &Item[string]{Value: "low priority", Priority: 1})
	heap.Push(&pq, &Item[string]{Value: "medium priority", Priority: 10})
	heap.Push(&pq, &Item[string]{Value: "high priority", Priority: 5})

	// Pop items from the priority queue
	fmt.Println("Priority queue contents (highest priority first):")
	for pq.Len() > 0 {
		item := heap.Pop(&pq).(*Item[string])
		fmt.Printf("Value: %s, Priority: %d\n", item.Value, item.Priority)
	}
}
```

2. Code a wrapper that adds synchronization, taking hint from [various blocking queue implementation](https://www.google.com/search?q=golang+blocking+queue)

```go
// https://github.com/adrianbrad/queue/blob/main/blocking.go
// https://github.com/theodesp/blockingQueues/blob/master/blockingQueue.go

// BlockingPriorityQueue wraps UnboundedPriorityQueue with thread safety.
type BlockingPriorityQueue[T any] struct {
	pq     UnboundedPriorityQueue[T] // The underlying priority queue
	mu     sync.Mutex                // Mutex for thread-safe access to the queue
	co     *sync.Cond                // Condition variable for signaling when the queue is not empty
	closed bool                      // Indicates if the queue is closed
}

// NewBlockingPriorityQueue initializes a new BlockingPriorityQueue.
func NewBlockingPriorityQueue[T any]() *BlockingPriorityQueue[T] {
	bpq := &BlockingPriorityQueue[T]{}
	// Initialize the condition variable with the mutex
	bpq.co = sync.NewCond(&bpq.mu)
	return bpq
}

// Len returns the length of the priority queue in a thread-safe manner.
func (pqw *BlockingPriorityQueue[T]) Len() int {
	pqw.mu.Lock()         // Acquire the lock to ensure thread-safe access
	defer pqw.mu.Unlock() // Release the lock when the function exits
	return pqw.pq.Len()
}

// Push adds an item to the priority queue in a thread-safe manner.
func (pqw *BlockingPriorityQueue[T]) Push(x *Item[T]) error {
	pqw.mu.Lock()         // Acquire the lock to ensure thread-safe access
	defer pqw.mu.Unlock() // Release the lock when the function exits

	if pqw.closed {
		return fmt.Errorf("queue is closed")
	}

	defer pqw.co.Signal() // Signal one waiting goroutine that an item has been added
	heap.Push(&pqw.pq, x) // Add the item to the underlying priority queue
	return nil
}

// Pop removes and returns the highest-priority item from the queue in a thread-safe manner.
func (pqw *BlockingPriorityQueue[T]) Pop() (*Item[T], error) {
	pqw.mu.Lock()         // Acquire the lock to ensure thread-safe access
	defer pqw.mu.Unlock() // Release the lock when the function exits

	// Wait until the queue is not empty or closed
	for pqw.pq.Len() <= 0 && !pqw.closed {
		pqw.co.Wait() // Release the lock and wait for a signal
	}

	if pqw.closed && pqw.pq.Len() == 0 {
		log.Debug().Msg("BlockingPriorityQueue Pop() closed")
		return nil, fmt.Errorf("queue is closed")
	}

	// Remove and return the highest-priority item
	return heap.Pop(&pqw.pq).(*Item[T]), nil
}

// Close marks the queue as closed and signals all waiting goroutines.
func (pqw *BlockingPriorityQueue[T]) Close() {
	pqw.mu.Lock()         // Acquire the lock to ensure thread-safe access
	defer pqw.mu.Unlock() // Release the lock when the function exits

	if !pqw.closed {
		pqw.closed = true
		pqw.co.Broadcast() // Wake up all waiting goroutines
	}
}
```

3. Code another wrapper that expose the `In` and `Out` channels to work with, taking hint from [various customized channels](https://www.google.com/search?q=golang+unbounded+channel)

```go
// https://github.com/golang-design/chann/blob/main/chann.go

// ChannelizedPriorityQueue wraps a BlockingPriorityQueue and provides in and out channels
// for interacting with the queue using a producer-consumer model.
type ChannelizedPriorityQueue[T any] struct {
	in  chan *Item[T]             // Buffered channel for incoming items
	out chan *Item[T]             // Unbuffered channel for outgoing items
	bpq *BlockingPriorityQueue[T] // Internal thread-safe priority queue
}

// NewChannelizedPriorityQueue initializes a new ChannelizedPriorityQueue.
func NewChannelizedPriorityQueue[T any]() *ChannelizedPriorityQueue[T] {
	cpq := &ChannelizedPriorityQueue[T]{
		in:  make(chan *Item[T], 16), // Buffered channel with size 16
		out: make(chan *Item[T]),     // Unbuffered channel
		bpq: NewBlockingPriorityQueue[T](),
	}

	// Start a goroutine to transfer items from the in channel to the internal queue
	go cpq.transferToQueue()

	// Start a goroutine to transfer items from the internal queue to the out channel
	go cpq.transferToOut()

	return cpq
}

// transferToQueue continuously reads from the in channel and pushes items to the internal queue.
func (cpq *ChannelizedPriorityQueue[T]) transferToQueue() {
	for item := range cpq.in {
		cpq.bpq.Push(item) // Push the item to the internal priority queue
	}
	log.Debug().Msg("ChannelizedPriorityQueue transferToQueue exited")
	// When the in channel is closed, and exhausted of all items, we can Close the bpq queue
	// transferToOut will still receive items until also exhausting the internal queue
	cpq.bpq.Close()
}

// transferToOut continuously pops items from the internal queue and sends them to the out channel.
func (cpq *ChannelizedPriorityQueue[T]) transferToOut() {
	for {
		item, err := cpq.bpq.Pop() // Pop the highest-priority item from the internal queue
		if err != nil {            // Closed
			close(cpq.out)
			log.Debug().Msg("ChannelizedPriorityQueue out channel closed")
			return
		}
		cpq.out <- item // Send the item to the out channel
	}
}

// In returns the input channel for adding items to the queue.
func (cpq *ChannelizedPriorityQueue[T]) In() chan<- *Item[T] {
	return cpq.in
}

// Out returns the output channel for consuming items from the queue.
func (cpq *ChannelizedPriorityQueue[T]) Out() <-chan *Item[T] {
	return cpq.out
}

// Close closes the in channel immediately and delays the closing of the out channel
// until all remaining items have been processed.
func (cpq *ChannelizedPriorityQueue[T]) Close() {
	// Close the in channel to stop accepting new items, transferToQueue will call bpq.Close()
	close(cpq.in)
	log.Debug().Msg("ChannelizedPriorityQueue in channel closed")

	// The out channel will be closed in transferToOut
}
```

I then used this priority queue as a "middleman" between two channels to illustrate the problem I am facing. Here is the driver code using this priority-queue custom channel:

```go
func main() {
	// Using ChannelizedPriorityQueue as a middleman between two channels here to illustrate
	// how ChannelizedPriorityQueue will be sent items and be received items from

	stringsFromProducer := make(chan string)
	// Start StringProducer
	go func() {
		StringProducer(stringsFromProducer)
		close(stringsFromProducer) // Close the channel after StringProducer is done
		log.Debug().Msg("pathsFromProducer closed")
	}()

	// Create a ChannelizedPriorityQueue to act as a middleman
	cpq := NewChannelizedPriorityQueue[string]()

	// Goroutine to transfer strings from the StringProducer to the ChannelizedPriorityQueue
	go func() {
		for path := range stringsFromProducer {
			item := &Item[string]{Value: path, Priority: len(path)} // Demo priority
			cpq.In() <- item
		}
		cpq.Close() // when stringsFromProducer is closed, close ChannelizedPriorityQueue also
		log.Debug().Msg("ChannelizedPriorityQueue closed")
	}()

	stringsToWorker := make(chan string)
	// Goroutine to transfer strings from the ChannelizedPriorityQueue to the workers
	go func() {
		for item := range cpq.Out() {
			stringsToWorker <- item.Value // Send the path to the workers
		}
		close(stringsToWorker) // Close it when ChannelizedPriorityQueue is closed
		log.Debug().Msg("pathsToWorker closed")
	}()

	numWorkers := 4 // Number of workers
	var wg sync.WaitGroup
	// Launch worker goroutines
	for range numWorkers {
		wg.Add(1)
		go func() {
			defer wg.Done()
			StringConsumer(stringsToWorker)
		}()
	}
	wg.Wait() // Wait for all workers to finish
}
```

For completeness, here are my simplified `StringConsumer` and `StringProducer` functions:

```go
func StringProducer(strings <-chan string) {
    for range 5 {
		str := rand.Text()
		log.Info().Str("str", str).Msg("Sending string")
		strings <- str
	}
}

func StringConsumer() {
    log.Info().Str("str", path).Msg("Consuming string")
}
```

### Problem:

`StringProducer` sends all strings, but `StringConsumer`s do not consume all strings some times.

Example output:
```
12:13AM INF Sending string str=UFG3FBPBKFZKAY3IGVSLJCTU73
12:13AM INF Sending string str=CQXTC4YTFUEXQIQCHVIWEXSN4Q
12:13AM INF Consuming string str=UFG3FBPBKFZKAY3IGVSLJCTU73
12:13AM INF Sending string str=ABFG6ZXKDU53DPGXK3MRA6VUTX
12:13AM INF Sending string str=L54QCVHLFBEMD6UQ2QXPMN6NST
12:13AM INF Consuming string str=CQXTC4YTFUEXQIQCHVIWEXSN4Q
12:13AM INF Sending string str=MWXBDAOQSWH4AFOPZ7QKQQSC4K
12:13AM DBG pathsFromProducer closed
12:13AM INF Consuming string str=ABFG6ZXKDU53DPGXK3MRA6VUTX
12:13AM DBG ChannelizedPriorityQueue transferToQueue exited
12:13AM DBG ChannelizedPriorityQueue in channel closed
12:13AM DBG BlockingPriorityQueue closed
12:13AM DBG ChannelizedPriorityQueue closed
12:13AM DBG BlockingPriorityQueue Pop() closed
12:13AM DBG ChannelizedPriorityQueue out channel closed
12:13AM DBG pathsToWorker closed
```

Where did I go wrong?